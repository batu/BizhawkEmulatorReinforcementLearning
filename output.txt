(210, 160, 3)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 5, 210, 160, 3)    0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 210, 160, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 128, 128, 3)       0         
_________________________________________________________________
conv1_pad (ZeroPadding2D)    (None, 130, 130, 3)       0         
_________________________________________________________________
conv1 (Conv2D)               (None, 64, 64, 32)        864       
_________________________________________________________________
conv1_bn (BatchNormalization (None, 64, 64, 32)        128       
_________________________________________________________________
conv1_relu (Activation)      (None, 64, 64, 32)        0         
_________________________________________________________________
conv_pad_1 (ZeroPadding2D)   (None, 66, 66, 32)        0         
_________________________________________________________________
conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       
_________________________________________________________________
conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       
_________________________________________________________________
conv_dw_1_relu (Activation)  (None, 64, 64, 32)        0         
_________________________________________________________________
conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      
_________________________________________________________________
conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       
_________________________________________________________________
conv_pw_1_relu (Activation)  (None, 64, 64, 64)        0         
_________________________________________________________________
conv_pad_2 (ZeroPadding2D)   (None, 66, 66, 64)        0         
_________________________________________________________________
conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       
_________________________________________________________________
conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       
_________________________________________________________________
conv_dw_2_relu (Activation)  (None, 32, 32, 64)        0         
_________________________________________________________________
conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      
_________________________________________________________________
conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       
_________________________________________________________________
conv_pw_2_relu (Activation)  (None, 32, 32, 128)       0         
_________________________________________________________________
conv_pad_3 (ZeroPadding2D)   (None, 34, 34, 128)       0         
_________________________________________________________________
conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      
_________________________________________________________________
conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       
_________________________________________________________________
conv_dw_3_relu (Activation)  (None, 32, 32, 128)       0         
_________________________________________________________________
conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     
_________________________________________________________________
conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       
_________________________________________________________________
conv_pw_3_relu (Activation)  (None, 32, 32, 128)       0         
_________________________________________________________________
conv_pad_4 (ZeroPadding2D)   (None, 34, 34, 128)       0         
_________________________________________________________________
conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      
_________________________________________________________________
conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       
_________________________________________________________________
conv_dw_4_relu (Activation)  (None, 16, 16, 128)       0         
_________________________________________________________________
conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     
_________________________________________________________________
conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      
_________________________________________________________________
conv_pw_4_relu (Activation)  (None, 16, 16, 256)       0         
_________________________________________________________________
conv_pad_5 (ZeroPadding2D)   (None, 18, 18, 256)       0         
_________________________________________________________________
conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      
_________________________________________________________________
conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      
_________________________________________________________________
conv_dw_5_relu (Activation)  (None, 16, 16, 256)       0         
_________________________________________________________________
conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     
_________________________________________________________________
conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      
_________________________________________________________________
conv_pw_5_relu (Activation)  (None, 16, 16, 256)       0         
_________________________________________________________________
conv_pad_6 (ZeroPadding2D)   (None, 18, 18, 256)       0         
_________________________________________________________________
conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      
_________________________________________________________________
conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      
_________________________________________________________________
conv_dw_6_relu (Activation)  (None, 8, 8, 256)         0         
_________________________________________________________________
conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    
_________________________________________________________________
conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_6_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_7 (ZeroPadding2D)   (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      
_________________________________________________________________
conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_dw_7_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    
_________________________________________________________________
conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_7_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_8 (ZeroPadding2D)   (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      
_________________________________________________________________
conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_dw_8_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    
_________________________________________________________________
conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_8_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_9 (ZeroPadding2D)   (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      
_________________________________________________________________
conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_dw_9_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    
_________________________________________________________________
conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_9_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_10 (ZeroPadding2D)  (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      
_________________________________________________________________
conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_dw_10_relu (Activation) (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    
_________________________________________________________________
conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_10_relu (Activation) (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_11 (ZeroPadding2D)  (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      
_________________________________________________________________
conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_dw_11_relu (Activation) (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    
_________________________________________________________________
conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_11_relu (Activation) (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_12 (ZeroPadding2D)  (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      
_________________________________________________________________
conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      
_________________________________________________________________
conv_dw_12_relu (Activation) (None, 4, 4, 512)         0         
_________________________________________________________________
conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    
_________________________________________________________________
conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      
_________________________________________________________________
conv_pw_12_relu (Activation) (None, 4, 4, 1024)        0         
_________________________________________________________________
conv_pad_13 (ZeroPadding2D)  (None, 6, 6, 1024)        0         
_________________________________________________________________
conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      
_________________________________________________________________
conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      
_________________________________________________________________
conv_dw_13_relu (Activation) (None, 4, 4, 1024)        0         
_________________________________________________________________
conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   
_________________________________________________________________
conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      
_________________________________________________________________
conv_pw_13_relu (Activation) (None, 4, 4, 1024)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 16384)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                524320    
_________________________________________________________________
dense_2 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_3 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_4 (Dense)              (None, 6)                 54        
=================================================================
Total params: 3,753,902
Trainable params: 718
Non-trainable params: 3,753,184
_________________________________________________________________
DQN.py hyperparameters have been saved!
gym_bizhawk.py hyperparameters have been saved!
Information saving is complete!
Training has started!
Training for 21600 steps ...
   458/21600: episode: 1, duration: 15.571s, episode steps: 458, steps per second: 29, episode reward: 100.000, mean reward: 0.218 [0.000, 25.000], mean action: 2.718 [0.000, 5.000], mean observation: 31.685 [0.000, 252.000], loss: 1.329115, mean_absolute_error: 1.190003, mean_q: 1.820826, mean_eps: 0.632007
   922/21600: episode: 2, duration: 19.478s, episode steps: 464, steps per second: 24, episode reward: 150.000, mean reward: 0.323 [0.000, 25.000], mean action: 3.002 [0.000, 5.000], mean observation: 31.838 [0.000, 252.000], loss: 0.345306, mean_absolute_error: 0.691416, mean_q: 1.169693, mean_eps: 0.522583
  1324/21600: episode: 3, duration: 16.865s, episode steps: 402, steps per second: 24, episode reward: 50.000, mean reward: 0.124 [0.000, 25.000], mean action: 3.604 [0.000, 5.000], mean observation: 31.439 [0.000, 252.000], loss: 0.105028, mean_absolute_error: 0.386261, mean_q: 0.698987, mean_eps: 0.380200
  1733/21600: episode: 4, duration: 17.378s, episode steps: 409, steps per second: 24, episode reward: 75.000, mean reward: 0.183 [0.000, 25.000], mean action: 3.743 [0.000, 5.000], mean observation: 31.593 [0.000, 252.000], loss: 0.057077, mean_absolute_error: 0.243789, mean_q: 0.417311, mean_eps: 0.246387
  2120/21600: episode: 5, duration: 16.516s, episode steps: 387, steps per second: 23, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.625 [0.000, 5.000], mean observation: 31.282 [0.000, 252.000], loss: 0.035994, mean_absolute_error: 0.230186, mean_q: 0.380028, mean_eps: 0.117311
  2508/21600: episode: 6, duration: 17.110s, episode steps: 388, steps per second: 23, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.832 [0.000, 5.000], mean observation: 31.281 [0.000, 252.000], loss: 0.030638, mean_absolute_error: 0.169658, mean_q: 0.307379, mean_eps: 0.075000
  2895/21600: episode: 7, duration: 16.198s, episode steps: 387, steps per second: 24, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.910 [0.000, 5.000], mean observation: 31.288 [0.000, 252.000], loss: 0.284797, mean_absolute_error: 0.193572, mean_q: 0.287051, mean_eps: 0.075000
  3281/21600: episode: 8, duration: 16.225s, episode steps: 386, steps per second: 24, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.907 [0.000, 5.000], mean observation: 31.291 [0.000, 252.000], loss: 0.020219, mean_absolute_error: 0.159681, mean_q: 0.332087, mean_eps: 0.075000
  3681/21600: episode: 9, duration: 16.752s, episode steps: 400, steps per second: 24, episode reward: 25.000, mean reward: 0.062 [0.000, 25.000], mean action: 3.950 [0.000, 5.000], mean observation: 31.325 [0.000, 252.000], loss: 0.265413, mean_absolute_error: 0.197842, mean_q: 0.341414, mean_eps: 0.075000
  4062/21600: episode: 10, duration: 15.902s, episode steps: 381, steps per second: 24, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.887 [0.000, 5.000], mean observation: 31.281 [0.000, 252.000], loss: 0.018641, mean_absolute_error: 0.174520, mean_q: 0.411893, mean_eps: 0.075000
  4454/21600: episode: 11, duration: 16.390s, episode steps: 392, steps per second: 24, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.867 [0.000, 5.000], mean observation: 31.284 [0.000, 252.000], loss: 0.011195, mean_absolute_error: 0.166880, mean_q: 0.412329, mean_eps: 0.075000
  4836/21600: episode: 12, duration: 16.036s, episode steps: 382, steps per second: 24, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.924 [0.000, 5.000], mean observation: 31.287 [0.000, 252.000], loss: 0.008163, mean_absolute_error: 0.165764, mean_q: 0.407516, mean_eps: 0.075000
  5219/21600: episode: 13, duration: 16.404s, episode steps: 383, steps per second: 23, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.864 [0.000, 5.000], mean observation: 31.290 [0.000, 252.000], loss: 0.013556, mean_absolute_error: 0.177071, mean_q: 0.401849, mean_eps: 0.075000
  5598/21600: episode: 14, duration: 16.508s, episode steps: 379, steps per second: 23, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.908 [0.000, 5.000], mean observation: 31.291 [0.000, 252.000], loss: 0.008309, mean_absolute_error: 0.173581, mean_q: 0.400726, mean_eps: 0.075000
  5990/21600: episode: 15, duration: 16.481s, episode steps: 392, steps per second: 24, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.872 [0.000, 5.000], mean observation: 31.286 [0.000, 252.000], loss: 0.006077, mean_absolute_error: 0.179546, mean_q: 0.400712, mean_eps: 0.075000
  6394/21600: episode: 16, duration: 16.964s, episode steps: 404, steps per second: 24, episode reward: 25.000, mean reward: 0.062 [0.000, 25.000], mean action: 3.834 [0.000, 5.000], mean observation: 31.340 [0.000, 252.000], loss: 0.007030, mean_absolute_error: 0.186316, mean_q: 0.402926, mean_eps: 0.075000
  6780/21600: episode: 17, duration: 16.270s, episode steps: 386, steps per second: 24, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.842 [0.000, 5.000], mean observation: 31.283 [0.000, 252.000], loss: 0.005271, mean_absolute_error: 0.181601, mean_q: 0.391771, mean_eps: 0.075000
  7169/21600: episode: 18, duration: 16.398s, episode steps: 389, steps per second: 24, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.866 [0.000, 5.000], mean observation: 31.294 [0.000, 252.000], loss: 0.002605, mean_absolute_error: 0.174776, mean_q: 0.375314, mean_eps: 0.075000
  7572/21600: episode: 19, duration: 16.963s, episode steps: 403, steps per second: 24, episode reward: 50.000, mean reward: 0.124 [0.000, 25.000], mean action: 3.851 [0.000, 5.000], mean observation: 31.376 [0.000, 252.000], loss: 0.004417, mean_absolute_error: 0.179982, mean_q: 0.372218, mean_eps: 0.075000
  7976/21600: episode: 20, duration: 17.091s, episode steps: 404, steps per second: 24, episode reward: 50.000, mean reward: 0.124 [0.000, 25.000], mean action: 3.800 [0.000, 5.000], mean observation: 31.332 [0.000, 252.000], loss: 0.004154, mean_absolute_error: 0.177706, mean_q: 0.354635, mean_eps: 0.075000
  8376/21600: episode: 21, duration: 16.953s, episode steps: 400, steps per second: 24, episode reward: 50.000, mean reward: 0.125 [0.000, 25.000], mean action: 3.882 [0.000, 5.000], mean observation: 31.336 [0.000, 252.000], loss: 0.004511, mean_absolute_error: 0.183340, mean_q: 0.362476, mean_eps: 0.075000
  8786/21600: episode: 22, duration: 17.680s, episode steps: 410, steps per second: 23, episode reward: 50.000, mean reward: 0.122 [0.000, 25.000], mean action: 3.705 [0.000, 5.000], mean observation: 31.337 [0.000, 252.000], loss: 0.003527, mean_absolute_error: 0.183165, mean_q: 0.354637, mean_eps: 0.075000
  9166/21600: episode: 23, duration: 16.071s, episode steps: 380, steps per second: 24, episode reward: 0.000, mean reward: 0.000 [0.000, 0.000], mean action: 3.668 [0.000, 5.000], mean observation: 31.291 [0.000, 252.000], loss: 0.258571, mean_absolute_error: 0.231966, mean_q: 0.376672, mean_eps: 0.075000
done, took 398.865 seconds
