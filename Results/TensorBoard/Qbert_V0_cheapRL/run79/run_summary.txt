_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 5, 210, 160, 3)    0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 128, 128, 3)       0         
_________________________________________________________________
lambda_2 (Lambda)            (None, 128, 128, 3)       0         
_________________________________________________________________
conv1_pad (ZeroPadding2D)    (None, 130, 130, 3)       0         
_________________________________________________________________
conv1 (Conv2D)               (None, 64, 64, 32)        864       
_________________________________________________________________
conv1_bn (BatchNormalization (None, 64, 64, 32)        128       
_________________________________________________________________
conv1_relu (Activation)      (None, 64, 64, 32)        0         
_________________________________________________________________
conv_pad_1 (ZeroPadding2D)   (None, 66, 66, 32)        0         
_________________________________________________________________
conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       
_________________________________________________________________
conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       
_________________________________________________________________
conv_dw_1_relu (Activation)  (None, 64, 64, 32)        0         
_________________________________________________________________
conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      
_________________________________________________________________
conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       
_________________________________________________________________
conv_pw_1_relu (Activation)  (None, 64, 64, 64)        0         
_________________________________________________________________
conv_pad_2 (ZeroPadding2D)   (None, 66, 66, 64)        0         
_________________________________________________________________
conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       
_________________________________________________________________
conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       
_________________________________________________________________
conv_dw_2_relu (Activation)  (None, 32, 32, 64)        0         
_________________________________________________________________
conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      
_________________________________________________________________
conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       
_________________________________________________________________
conv_pw_2_relu (Activation)  (None, 32, 32, 128)       0         
_________________________________________________________________
conv_pad_3 (ZeroPadding2D)   (None, 34, 34, 128)       0         
_________________________________________________________________
conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      
_________________________________________________________________
conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       
_________________________________________________________________
conv_dw_3_relu (Activation)  (None, 32, 32, 128)       0         
_________________________________________________________________
conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     
_________________________________________________________________
conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       
_________________________________________________________________
conv_pw_3_relu (Activation)  (None, 32, 32, 128)       0         
_________________________________________________________________
conv_pad_4 (ZeroPadding2D)   (None, 34, 34, 128)       0         
_________________________________________________________________
conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      
_________________________________________________________________
conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       
_________________________________________________________________
conv_dw_4_relu (Activation)  (None, 16, 16, 128)       0         
_________________________________________________________________
conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     
_________________________________________________________________
conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      
_________________________________________________________________
conv_pw_4_relu (Activation)  (None, 16, 16, 256)       0         
_________________________________________________________________
conv_pad_5 (ZeroPadding2D)   (None, 18, 18, 256)       0         
_________________________________________________________________
conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      
_________________________________________________________________
conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      
_________________________________________________________________
conv_dw_5_relu (Activation)  (None, 16, 16, 256)       0         
_________________________________________________________________
conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     
_________________________________________________________________
conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      
_________________________________________________________________
conv_pw_5_relu (Activation)  (None, 16, 16, 256)       0         
_________________________________________________________________
conv_pad_6 (ZeroPadding2D)   (None, 18, 18, 256)       0         
_________________________________________________________________
conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      
_________________________________________________________________
conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      
_________________________________________________________________
conv_dw_6_relu (Activation)  (None, 8, 8, 256)         0         
_________________________________________________________________
conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    
_________________________________________________________________
conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_6_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_7 (ZeroPadding2D)   (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      
_________________________________________________________________
conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_dw_7_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    
_________________________________________________________________
conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_7_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_8 (ZeroPadding2D)   (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      
_________________________________________________________________
conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_dw_8_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    
_________________________________________________________________
conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_8_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_9 (ZeroPadding2D)   (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      
_________________________________________________________________
conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_dw_9_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    
_________________________________________________________________
conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_9_relu (Activation)  (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_10 (ZeroPadding2D)  (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      
_________________________________________________________________
conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_dw_10_relu (Activation) (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    
_________________________________________________________________
conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_10_relu (Activation) (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_11 (ZeroPadding2D)  (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      
_________________________________________________________________
conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_dw_11_relu (Activation) (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    
_________________________________________________________________
conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      
_________________________________________________________________
conv_pw_11_relu (Activation) (None, 8, 8, 512)         0         
_________________________________________________________________
conv_pad_12 (ZeroPadding2D)  (None, 10, 10, 512)       0         
_________________________________________________________________
conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      
_________________________________________________________________
conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      
_________________________________________________________________
conv_dw_12_relu (Activation) (None, 4, 4, 512)         0         
_________________________________________________________________
conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    
_________________________________________________________________
conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      
_________________________________________________________________
conv_pw_12_relu (Activation) (None, 4, 4, 1024)        0         
_________________________________________________________________
conv_pad_13 (ZeroPadding2D)  (None, 6, 6, 1024)        0         
_________________________________________________________________
conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      
_________________________________________________________________
conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      
_________________________________________________________________
conv_dw_13_relu (Activation) (None, 4, 4, 1024)        0         
_________________________________________________________________
conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   
_________________________________________________________________
conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      
_________________________________________________________________
conv_pw_13_relu (Activation) (None, 4, 4, 1024)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 16384)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                524320    
_________________________________________________________________
dense_2 (Dense)              (None, 16)                528       
_________________________________________________________________
dense_3 (Dense)              (None, 8)                 136       
_________________________________________________________________
dense_4 (Dense)              (None, 6)                 54        
=================================================================
Total params: 3,753,902
Trainable params: 718
Non-trainable params: 3,753,184
_________________________________________________________________


def lambda_resize(input_tensor):
    import tensorflow as tf_out
    return tf_out.image.resize_images(input_tensor, (128, 128))

def relu6(x):
  return K.relu(x, max_value=6)

with CustomObjectScope({'relu6': relu6}):
        window_length = 5
        memory_size = 2048
        batch_size = 1
        env = gym.make(ENV_NAME)


        input_tensor = Input((5, 210, 160, 3,))
        input_tensor = Lambda(lambda frame: frame[0,0:1], output_shape=(128, 128, 3))(input_tensor)
        input_tensor = Lambda(lambda_resize)(input_tensor)

        mobilenet_model = MobileNet(weights='imagenet', include_top=False, input_shape=(128, 128, 3), input_tensor=input_tensor )
        #inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3), input_tensor=input_tensor )

        for layer in mobilenet_model.layers:
            layer.trainable = False

        # add a global spatial average pooling layer
        x = mobilenet_model.output
        x = Flatten()(x)
        x = Dense(32, activation='relu',  trainable=False)(x)
        x = Dense(16, activation='relu',  trainable=True)(x)
        x = Dense(8, activation='relu',  trainable=True)(x)

        predictions = Dense(nb_actions, activation='linear',  trainable=True)(x)

        # this is the model we will train
        model = Model(inputs=mobilenet_model.input, outputs=predictions)


        episode_count = 8
        step_count = 21600
        memory = SequentialMemory(limit=memory_size, window_length=window_length)
        policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=.75, value_min=0.075, value_test=0,
                                     nb_steps=episode_count * 512 / 2)

        dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy, memory=memory,
               nb_steps_warmup=256, gamma=.925, target_model_update=1e-2,
               train_interval=4, batch_size=batch_size, delta_clip=1., enable_dueling_network=True, dueling_type="avg")

        dqn.compile(Adam(lr=1e-3), metrics=['mae'])

        dqn.fit(env, nb_steps=step_count, visualize=True, verbose=2, callbacks=[callbacks.TensorBoard(log_dir=run_path, write_graph=True, write_images=True)])


		self.EPISODE_LENGTH = 768
		self.ACTION_LENGTH = 12

		# This is the action space.
		self.action_dict = {
			0: "A",
			1: "Right",
			2: "Left",
			3: "B",
			4: ""
			# 3: "Down",
			# 4: "B"
		}

		# This is the state
		return current_vector_with_memory_from_ss_plus_last_action()

		def plusone_increase_minus_half_decrease_or_stationary():
			distance = self.get_distance()
			delta = distance - self.last_distance

			reward = -.5
			# The reward amounts
			if delta > 0:
				reward = 1
			elif delta < 0:
				reward = -.5

			self.last_distance = distance
			return reward

		def distance_traveled_between_frames_minus_for_nochange():
			distance = self.get_distance()
			delta = distance - self.last_distance

			self.last_distance = distance
			if delta == 0:
				delta = -0.1
			if delta > 30:
				delta = 0
			if delta < -1250:
				delta = 0
			return delta

		# The reward is:
		reward = increase_the_max_bounding_box()
